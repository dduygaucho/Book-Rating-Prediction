{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook relies primarily on \n",
        "https://www.tensorflow.org/text/tutorials/classify_text_with_bert\n",
        "\n",
        "for faster GPU computation facilitated by Tensorflow. Have no option other than this for fast computation\n",
        "\n",
        "This notebook recustomises dataset, input, output for model. It also adds a level of customization in the architecture.\n",
        "\n",
        "Just add extra class_weight for training to get small-bert class_weights\n",
        "\n",
        "To load models:\n",
        "normal version: best_path = best/best_model/best.ckpt\n",
        "\n",
        "classweight version: best_path = small_bert/class_weights/best.ckpt\n"
      ],
      "metadata": {
        "id": "0ietvX_htoqs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCjmX4zTCkRK"
      },
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "q-YbjCkzw0yU",
        "outputId": "d93c5248-0512-46c0-afa7-99d3f03fd26e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-text==2.11.0\n",
            "  Downloading tensorflow_text-2.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text==2.11.0) (0.13.0)\n",
            "Collecting tensorflow<2.12,>=2.11.0 (from tensorflow-text==2.11.0)\n",
            "  Downloading tensorflow-2.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (3.8.0)\n",
            "Collecting keras<2.12,>=2.11.0 (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0)\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (16.0.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (23.1)\n",
            "Collecting protobuf<3.20,>=3.9.2 (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0)\n",
            "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (1.16.0)\n",
            "Collecting tensorboard<2.12,>=2.11 (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0)\n",
            "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.12,>=2.11.0 (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0)\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (0.40.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (2.17.3)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0)\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (2.27.1)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0)\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (3.2.2)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard-data-server, protobuf, keras, google-auth-oauthlib, tensorboard, tensorflow, tensorflow-text\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.0\n",
            "    Uninstalling tensorboard-data-server-0.7.0:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.0.0\n",
            "    Uninstalling google-auth-oauthlib-1.0.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.2\n",
            "    Uninstalling tensorboard-2.12.2:\n",
            "      Successfully uninstalled tensorboard-2.12.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-datasets 4.9.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-auth-oauthlib-0.4.6 keras-2.11.0 protobuf-3.19.6 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorflow-2.11.1 tensorflow-estimator-2.11.0 tensorflow-text-2.11.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# A dependency of the preprocessing for BERT inputs\n",
        "!pip install tensorflow-text==2.11.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5w_XlxN1IsRJ"
      },
      "source": [
        "You will use the AdamW optimizer from [tensorflow/models](https://github.com/tensorflow/models)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "b-P1ZOA0FkVJ",
        "outputId": "498111f1-2db6-4246-827a-c81d633c865f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.1/175.1 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.6/240.6 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m108.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyyaml (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q tf-models-official"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip3 install tf-models-official"
      ],
      "metadata": {
        "id": "PU9lqI-y0Ij-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_XgTpm9ZxoN9",
        "outputId": "83df0030-6e1d-4922-f909-92c426ef496c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization  # to create AdamW optimizer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import io\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/My Drive/Bookpred/Assignment 2\"\n",
        "%cd {path}\n",
        "!ls"
      ],
      "metadata": {
        "id": "5N5UKutO0VCm",
        "outputId": "8d2bc7f1-14ec-4162-e950-59a3242c539f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Bookpred/Assignment 2\n",
            " 8.prep_IMDB.ipynb\n",
            "'Assignment 2 Track.gdoc'\n",
            " bert\n",
            " best_model\n",
            " book_rating_test.csv\n",
            " book_rating_train.csv\n",
            " book_text_features_countvec\n",
            " book_text_features_doc2vec\n",
            " book_text_features_tfidf\n",
            " COMP30027_Project2_spec_2023S1.pdf\n",
            "'Copy of model.png'\n",
            " English\n",
            "'English (1)'\n",
            "'Feature engineering.ipynb'\n",
            " full_dataset\n",
            " history.pkl\n",
            " history_v.pkl\n",
            " lgbm_class_weight.joblib\n",
            " lgbm_cv.joblib\n",
            " lgbm_cw.joblib\n",
            " lgbm_normal.joblib\n",
            " lgbm_oversampling.joblib\n",
            " matrix.npz\n",
            " Model.ipynb\n",
            " model.png\n",
            " multilingual_best\n",
            " multilingual_epochs\n",
            " output.csv\n",
            " Oversampling\n",
            " Oversampling_real\n",
            " partition\n",
            " random_forest_doc.joblib\n",
            " random_forest.joblib\n",
            " random_forest_num.joblib\n",
            " rf_cw.joblib\n",
            " rf_normal.joblib\n",
            " rf_smote.joblib\n",
            " small_bert\n",
            " smallbert_class_weight.png\n",
            " smallbert_focal.png\n",
            " smallbert_normal.png\n",
            " smallbert_oversampling_minority.png\n",
            " Test\n",
            " test_focal.npy\n",
            " text_features_description.ipynb\n",
            " train_ind.pkl\n",
            " Validation\n",
            " val_ind.pkl\n",
            " val_output_smallbert_class_weights.pkl\n",
            " val_output_smallbert_cw.pkl\n",
            " val_output_smallbert_focal.pkl\n",
            " val_output_smallbert_normal.pkl\n",
            " val_output_smallbert_norm.pkl\n",
            " val_output_smallbert_oversampling.pkl\n",
            " val_prediction_smallbert_class_weights.pkl\n",
            " val_prediction_smallbert_cw.pkl\n",
            " val_prediction_smallbert_focal.pkl\n",
            " val_prediction_smallbert_normal.pkl\n",
            " val_prediction_smallbert_norm.pkl\n",
            " val_prediction_smallbert_oversampling.pkl\n",
            " xgb_model_doc.pkl\n",
            " xgb_model.pkl\n",
            " X_res.npz\n",
            " y_pred_best_multilingual.txt\n",
            " y_pred_best.txt\n",
            " y_pred_pretrain1.txt\n",
            " y_pred_test_smallbert_classweight.txt\n",
            " y_pred_test_smallbert.txt\n",
            " y_pred_val_multilingual.txt\n",
            " y_pred_val_smallbert_classweight.txt\n",
            " y_pred_val.txt\n",
            " y_res.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pOdqCMoQDRJL",
        "outputId": "a9f6fe15-5329-4a30-f1ca-a6f1e560d7cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['4.0', '3.0', '5.0']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"book_rating_train.csv\")\n",
        "train_df\n",
        "\n",
        "test_df = pd.read_csv(\"book_rating_test.csv\")\n",
        "test_df\n",
        "\n",
        "\n",
        "train_dir = \"/content/drive/MyDrive/Bookpred/Assignment 2/English\"\n",
        "os.listdir(train_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6IwI_2bcIeX8",
        "outputId": "0c0f43c7-09da-4bc5-f85a-ab1648961366",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 23011 files belonging to 3 classes.\n",
            "Using 18409 files for training.\n",
            "Found 23011 files belonging to 3 classes.\n",
            "Using 4602 files for validation.\n",
            "Found 5766 files belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "batch_size = 32\n",
        "seed = 42\n",
        "\n",
        "raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    train_dir,\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    seed=seed)\n",
        "\n",
        "class_names = raw_train_ds.class_names\n",
        "train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "val_dataset = tf.keras.utils.text_dataset_from_directory(\n",
        "    train_dir,\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed=seed)\n",
        "\n",
        "\n",
        "val_ds = val_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "\n",
        "test_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    \"/content/drive/MyDrive/Bookpred/Assignment 2/Test\", labels = None, label_mode =None, batch_size = batch_size, seed = seed, shuffle = False\n",
        ")\n",
        "\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGm10A5HRGXp"
      },
      "source": [
        "Let's take a look at a few reviews."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuxDkcvVIoev",
        "outputId": "c9ea925e-4906-4ba0-e8c9-a6ad89a64d44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review: b'\"\"I can assure you,\" said the young man, \"that it will take a very tangible ghost to frighten me.\"\"So says the foolishly brave narrator of H. G. Wells\\'s \"The Red Room,\" one of the thirteen great ghost stories gathered together in this deluxe illustrated volume. Selected and illustrated by Barry Moser, a master of the macabre, these spooky tales will send a shiver down the spine of even the bravest reader.This new edition includes classic masterpieces of horror by H. P. Lovecraft, Brain Stoker, Richard Middleton, and Arthur Conan Doyle. There are also several chilling modern tales of the supernatural by such authors as Madeleine L\\'Engle and Joyce Carol Oates to petrify even the most seasoned explorer of the dark realms.From the slowly gathering dread of being caught in the grips of a haunted house to the sure, sharp horror of realization that overcomes one entering the spirit world, nothing compares to the thrill of these tales from the great beyond. With Barry Moser\\'s fourteen eerie watercolors, this collection is sure to satisfy readers with an insatiable taste for terror, as well as those who simply love the chill down the spine that comes from reading a great ghost story.'\n",
            "Label : 0 (3.0)\n",
            "Review: b'\"Mom, Dad, I\\'m gay.\" When a parent hears these words, the initial shock is often followed by feelings ranging from anger and denial to fear and guilt. It\\'s also the beginning of a difficult journey that, with understanding and emotional support, can lead to acceptance and beyond.Now fully revised and updated, Beyond Acceptance by co-authors Carolyn W. Griffin, Marian J. Wirth, and Arthur G. Wirth remains a ground-breaking book that provides parents the comfort and knowledge they need to accept the gay children and build stronger family relationships. Based on the experiences of other parents, this book lets them know they are not alone and helps them through the emotional stages leading to reconciliation with their children.'\n",
            "Label : 1 (4.0)\n",
            "Review: b'Reading paragraphsIn 1991, two tourists hiking in the Alps saw something very odd sticking out of the snow. At first it looked like a doll\\xe2\\x80\\x99s head. But it wasn\\xe2\\x80\\x99t. It was a man, frozen in the ice for 5,000 years. Ice Mummy\\xe2\\x80\\x94first published by Random House in 1998\\xe2\\x80\\x94tells the story of this amazing discovery, from the struggle to remove the mummy from his icy grave to the creation of his final resting place: a specially designed refrigeration chamber in his own museum in Bolzano, Italy.Now updated to include shocking new evidence that the Iceman was murdered\\xe2\\x80\\x94shot with an arrow after hand-to-hand combat with an assailant\\xe2\\x80\\x94Ice Mummy will provide young readers with more chills than ever!From the Trade Paperback edition.'\n",
            "Label : 1 (4.0)\n"
          ]
        }
      ],
      "source": [
        "for text_batch, label_batch in train_ds.take(1):\n",
        "  for i in range(3):\n",
        "    print(f'Review: {text_batch.numpy()[i]}')\n",
        "    label = label_batch.numpy()[i]\n",
        "    print(f'Label : {label} ({class_names[label]})')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "y8_ctG55-uTX",
        "outputId": "2995e5a6-90a1-4f0d-d701-c4436562a4ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
            "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
          ]
        }
      ],
      "source": [
        "#@title Choose a BERT model to fine-tune\n",
        "\n",
        "bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8'  #@param [\"bert_en_uncased_L-12_H-768_A-12\", \"bert_en_cased_L-12_H-768_A-12\", \"bert_multi_cased_L-12_H-768_A-12\", \"small_bert/bert_en_uncased_L-2_H-128_A-2\", \"small_bert/bert_en_uncased_L-2_H-256_A-4\", \"small_bert/bert_en_uncased_L-2_H-512_A-8\", \"small_bert/bert_en_uncased_L-2_H-768_A-12\", \"small_bert/bert_en_uncased_L-4_H-128_A-2\", \"small_bert/bert_en_uncased_L-4_H-256_A-4\", \"small_bert/bert_en_uncased_L-4_H-512_A-8\", \"small_bert/bert_en_uncased_L-4_H-768_A-12\", \"small_bert/bert_en_uncased_L-6_H-128_A-2\", \"small_bert/bert_en_uncased_L-6_H-256_A-4\", \"small_bert/bert_en_uncased_L-6_H-512_A-8\", \"small_bert/bert_en_uncased_L-6_H-768_A-12\", \"small_bert/bert_en_uncased_L-8_H-128_A-2\", \"small_bert/bert_en_uncased_L-8_H-256_A-4\", \"small_bert/bert_en_uncased_L-8_H-512_A-8\", \"small_bert/bert_en_uncased_L-8_H-768_A-12\", \"small_bert/bert_en_uncased_L-10_H-128_A-2\", \"small_bert/bert_en_uncased_L-10_H-256_A-4\", \"small_bert/bert_en_uncased_L-10_H-512_A-8\", \"small_bert/bert_en_uncased_L-10_H-768_A-12\", \"small_bert/bert_en_uncased_L-12_H-128_A-2\", \"small_bert/bert_en_uncased_L-12_H-256_A-4\", \"small_bert/bert_en_uncased_L-12_H-512_A-8\", \"small_bert/bert_en_uncased_L-12_H-768_A-12\", \"albert_en_base\", \"electra_small\", \"electra_base\", \"experts_pubmed\", \"experts_wiki_books\", \"talking-heads_base\"]\n",
        "\n",
        "map_name_to_handle = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
        "    'albert_en_base':\n",
        "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
        "    'electra_small':\n",
        "        'https://tfhub.dev/google/electra_small/2',\n",
        "    'electra_base':\n",
        "        'https://tfhub.dev/google/electra_base/2',\n",
        "    'experts_pubmed':\n",
        "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
        "    'experts_wiki_books':\n",
        "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
        "    'talking-heads_base':\n",
        "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
        "}\n",
        "\n",
        "map_model_to_preprocess = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
        "    'albert_en_base':\n",
        "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
        "    'electra_small':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'electra_base':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_pubmed':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_wiki_books':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'talking-heads_base':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "}\n",
        "\n",
        "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
        "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
        "\n",
        "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
        "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0SQi-jWd_jzq"
      },
      "outputs": [],
      "source": [
        "# max_length = 512\n",
        "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "r9-zCzJpnuwS",
        "outputId": "faec7b62-ea86-44e2-8e88-ed6b388cce4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys       : ['input_type_ids', 'input_mask', 'input_word_ids']\n",
            "Shape      : (1, 128)\n",
            "Word Ids   : [ 101 2023 2003 2107 2019 6429 3185  999  102    0    0    0]\n",
            "Input Mask : [1 1 1 1 1 1 1 1 1 0 0 0]\n",
            "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "text_test = ['this is such an amazing movie!']\n",
        "text_preprocessed = bert_preprocess_model(text_test)\n",
        "\n",
        "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
        "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
        "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
        "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
        "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKnLPSEmtp9i"
      },
      "source": [
        "## Using the BERT model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tXxYpK8ixL34"
      },
      "outputs": [],
      "source": [
        "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_OoF9mebuSZc",
        "outputId": "a070610d-c087-4188-b265-e14360e19c9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded BERT: https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
            "Pooled Outputs Shape:(1, 512)\n",
            "Pooled Outputs Values:[ 0.76262873  0.9928099  -0.18611872  0.36673853  0.1523371   0.65504426\n",
            "  0.9681154  -0.94862705  0.00216182 -0.9877732   0.06842728 -0.97630584]\n",
            "Sequence Outputs Shape:(1, 128, 512)\n",
            "Sequence Outputs Values:[[-0.28946307  0.34321266  0.33231518 ...  0.21300897  0.71020764\n",
            "  -0.05771176]\n",
            " [-0.2874206   0.3198098  -0.23018597 ...  0.5845501  -0.21329726\n",
            "   0.72692066]\n",
            " [-0.6615712   0.68876785 -0.8743292  ...  0.10877268 -0.2617322\n",
            "   0.4785534 ]\n",
            " ...\n",
            " [-0.22561154 -0.28925663 -0.07064398 ...  0.47566003  0.8327717\n",
            "   0.40025344]\n",
            " [-0.29824272 -0.27473173 -0.05450511 ...  0.48849759  1.0955356\n",
            "   0.18163322]\n",
            " [-0.44378266  0.00930682  0.07223728 ...  0.17290092  1.1833241\n",
            "   0.07898061]]\n"
          ]
        }
      ],
      "source": [
        "bert_results = bert_model(text_preprocessed)\n",
        "\n",
        "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
        "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
        "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
        "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
        "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "aksj743St9ga"
      },
      "outputs": [],
      "source": [
        "def build_classifier_model():\n",
        "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
        "  encoder_inputs = preprocessing_layer(text_input)\n",
        "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
        "  outputs = encoder(encoder_inputs)\n",
        "  net = outputs['pooled_output']\n",
        "  net = tf.keras.layers.Dropout(0.2)(net)\n",
        "  net = tf.keras.layers.Dense(3, activation=None, name='classifier')(net)\n",
        "  return tf.keras.Model(text_input, net)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def build_classifier_model():\n",
        "#   text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "#   preprocessor = hub.load(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "\n",
        "#   tokenize = hub.KerasLayer(preprocessor.tokenize)\n",
        "#   tokenized_inputs = [tokenize(segment) for segment in text_inputs]\n",
        "\n",
        "#   seq_length = 256  # Your choice here.\n",
        "#   bert_pack_inputs = hub.KerasLayer(\n",
        "#     preprocessor.bert_pack_inputs,\n",
        "#     arguments=dict(seq_length=seq_length), name = 'preprocessing')  # Optional argument.\n",
        "#   encoder_inputs = bert_pack_inputs(tokenized_inputs)\n",
        "#   # preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
        "#   # encoder_inputs = preprocessing_layer(text_input)\n",
        "#   encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
        "#   outputs = encoder(encoder_inputs)\n",
        "#   net = outputs['pooled_output']\n",
        "#   net = tf.keras.layers.Dropout(0.2)(net)\n",
        "#   net = tf.keras.layers.Dense(3, activation=None, name='classifier')(net)\n",
        "#   return tf.keras.Model(text_input, net)"
      ],
      "metadata": {
        "id": "kkyzuBBn-cBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "mGMF8AZcB2Zy"
      },
      "outputs": [],
      "source": [
        "classifier_model = build_classifier_model()\n",
        "bert_raw_result = classifier_model(tf.constant(text_test))\n",
        "# print(tf.sigmoid(bert_raw_result))`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.nn.softmax(bert_raw_result)"
      ],
      "metadata": {
        "id": "2F_q1qfV-nts",
        "outputId": "8a73b318-c4dc-4404-ca5d-c8bde3671737",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[0.49923152, 0.2862428 , 0.2145257 ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EmzyHZXKIpm",
        "outputId": "e89a6cda-9e83-4f8d-cd99-b1bfdfc8dbb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "\n",
        "tf.keras.utils.plot_model(classifier_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbUWoZMwc302"
      },
      "source": [
        "## Model training\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpJ3xcwDT56v"
      },
      "source": [
        "### Loss function\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OWPOZE-L3AgE"
      },
      "outputs": [],
      "source": [
        "loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "\n",
        "metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "P9eP2y9dbw32"
      },
      "outputs": [],
      "source": [
        "epochs = 5\n",
        "steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
        "num_train_steps = steps_per_epoch * epochs\n",
        "num_warmup_steps = int(0.1*num_train_steps)\n",
        "\n",
        "init_lr = 3e-5\n",
        "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                                          num_train_steps=num_train_steps,\n",
        "                                          num_warmup_steps=num_warmup_steps,\n",
        "                                          optimizer_type='adamw')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "# define the checkpoint paths for saving weights after each epoch and the best model\n",
        "weights_path = 'small_bert/weights_epoch_{epoch:02d}.ckpt'  \n",
        "best_path = 'small_bert/best_model/best.ckpt'\n",
        "\n",
        "# use two ModelCheckpoint callbacks to save the weights after each epoch and the best model\n",
        "# weights_callback = ModelCheckpoint(filepath=weights_path, save_weights_only=True, save_freq='epoch')\n",
        "best_callback = ModelCheckpoint(filepath=best_path, save_best_only=True, monitor='val_accuracy', mode='max', verbose = 1)\n",
        "\n"
      ],
      "metadata": {
        "id": "PJw4tyWC_1Rk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-7GPDhR98jsD"
      },
      "outputs": [],
      "source": [
        "classifier_model.compile(optimizer=optimizer,\n",
        "                         loss=loss,\n",
        "                         metrics=metrics)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def return_class_weight(train_df):\n",
        "  answer= {0: 0, 1:0, 2:0}\n",
        "  labels = [3,4,5]\n",
        "\n",
        "  for label in labels:\n",
        "    freq = len(train_df[train_df['rating_label'] == label])/len(train_df)\n",
        "    answer[label - 3] = 1/(freq*2)\n",
        "\n",
        "  return answer\n",
        "\n",
        "freq = return_class_weight(train_df)"
      ],
      "metadata": {
        "id": "coYFz68TBQMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtfDFAnN_Neu",
        "outputId": "3a9273da-635d-424c-95ea-f14eccf7725d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model with https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
            "Epoch 1/5\n",
            "576/576 [==============================] - ETA: 0s - loss: 1.5596 - accuracy: 0.4686\n",
            "Epoch 1: val_accuracy improved from -inf to 0.55054, saving model to small_bert/class_weights/best.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 124). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r576/576 [==============================] - 1590s 3s/step - loss: 1.5596 - accuracy: 0.4686 - val_loss: 0.8015 - val_accuracy: 0.5505\n",
            "Epoch 2/5\n",
            "576/576 [==============================] - ETA: 0s - loss: 1.3324 - accuracy: 0.5494\n",
            "Epoch 2: val_accuracy improved from 0.55054 to 0.60065, saving model to small_bert/class_weights/best.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 124). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r576/576 [==============================] - 165s 286ms/step - loss: 1.3324 - accuracy: 0.5494 - val_loss: 0.7983 - val_accuracy: 0.6007\n",
            "Epoch 3/5\n",
            "576/576 [==============================] - ETA: 0s - loss: 1.1523 - accuracy: 0.6022\n",
            "Epoch 3: val_accuracy improved from 0.60065 to 0.67983, saving model to small_bert/class_weights/best.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 124). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r576/576 [==============================] - 166s 288ms/step - loss: 1.1523 - accuracy: 0.6022 - val_loss: 0.6723 - val_accuracy: 0.6798\n",
            "Epoch 4/5\n",
            "576/576 [==============================] - ETA: 0s - loss: 1.0692 - accuracy: 0.6509\n",
            "Epoch 4: val_accuracy did not improve from 0.67983\n",
            "576/576 [==============================] - 158s 274ms/step - loss: 1.0692 - accuracy: 0.6509 - val_loss: 0.6674 - val_accuracy: 0.6714\n",
            "Epoch 5/5\n",
            "576/576 [==============================] - ETA: 0s - loss: 1.0047 - accuracy: 0.6634\n",
            "Epoch 5: val_accuracy did not improve from 0.67983\n",
            "576/576 [==============================] - 161s 279ms/step - loss: 1.0047 - accuracy: 0.6634 - val_loss: 0.6674 - val_accuracy: 0.6714\n"
          ]
        }
      ],
      "source": [
        "print(f'Training model with {tfhub_handle_encoder}')\n",
        "history = classifier_model.fit(x=train_ds,\n",
        "                               validation_data=val_ds,\n",
        "                               epochs=epochs, callbacks = [best_callback],\n",
        "                               #class_weight = freq\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBthMlTSV8kn"
      },
      "source": [
        "### Evaluate the model\n",
        "\n",
        "Let's see how the model performs. Two values will be returned. Loss (a number which represents the error, lower values are better), and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slqB-urBV9sP"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = classifier_model.evaluate(test_ds)\n",
        "\n",
        "print(f'Loss: {loss}')\n",
        "print(f'Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fiythcODf0xo"
      },
      "outputs": [],
      "source": [
        "history_dict = history.history\n",
        "print(history_dict.keys())\n",
        "\n",
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "fig = plt.figure(figsize=(10, 6), dpi = 600)\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "# r is for \"solid red line\"\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "# plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(epochs, acc, 'r', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "plt.savefig(\"smallbert_normal.png\", bbox_inches = 'tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = tf.keras.utils.text_dataset_from_directory(\n",
        "    \"/content/drive/MyDrive/Bookpred/Assignment 2/Validation\",\n",
        "    batch_size=batch_size,\n",
        "    validation_split=None,\n",
        "    seed=seed)\n",
        "\n",
        "val_ds = val_dataset.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5py9IH5eIEt",
        "outputId": "f6465e90-d35f-4f5d-c7bf-6f4793b9ade0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4610 files belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ShcvqJAgVera",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49908aec-3517-4fa9-ad02-6a4f14021563"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fe045802560>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "reloaded_model = build_classifier_model()\n",
        "reloaded_model.compile(optimizer=optimizer,\n",
        "                         loss=loss,\n",
        "                         metrics=metrics)\n",
        "reloaded_model.load_weights(best_path)\n",
        "\n",
        "\n",
        "# val_prediction = reloaded_model.predict(val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print('GPU device not found')\n",
        "else:\n",
        "  print('Found GPU at: {}'.format(device_name))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5j2_5R7ao_h",
        "outputId": "7ed52071-5ead-4cd4-c0ea-1cfef3b31cef"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the class names from the dataset object\n",
        "class_names = val_dataset.class_names\n",
        "class_names = [3,4,5]\n",
        "val_output = []\n",
        "val_prediction = []\n",
        "# Print all the labels of all instances in the dataset\n",
        "for text_batch, label_batch in val_ds:\n",
        "    # print(label_batch)\n",
        "    label_names = [class_names[i] for i in label_batch.numpy()]\n",
        "    y_pred = tf.nn.softmax(reloaded_model.predict(text_batch)).numpy().argmax(axis = 1) + 3\n",
        "    # print(label_names, len(label_names))\n",
        "    # print(y_pred, len(y_pred))\n",
        "    val_output.extend(label_names)\n",
        "    val_prediction.extend(y_pred)\n",
        "    # break\n",
        "print(len(val_output))\n",
        "print(len(val_prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYlChS34Zm3L",
        "outputId": "920b01a4-0d36-4d87-8035-1c2f7f70a96c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 774ms/step\n",
            "1/1 [==============================] - 0s 150ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 86ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 88ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 88ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 88ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 101ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "1/1 [==============================] - 0s 106ms/step\n",
            "1/1 [==============================] - 0s 142ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 130ms/step\n",
            "1/1 [==============================] - 0s 137ms/step\n",
            "1/1 [==============================] - 0s 156ms/step\n",
            "1/1 [==============================] - 0s 144ms/step\n",
            "1/1 [==============================] - 0s 141ms/step\n",
            "1/1 [==============================] - 0s 144ms/step\n",
            "1/1 [==============================] - 0s 140ms/step\n",
            "1/1 [==============================] - 0s 145ms/step\n",
            "1/1 [==============================] - 0s 152ms/step\n",
            "1/1 [==============================] - 0s 149ms/step\n",
            "1/1 [==============================] - 0s 150ms/step\n",
            "1/1 [==============================] - 0s 156ms/step\n",
            "1/1 [==============================] - 0s 145ms/step\n",
            "1/1 [==============================] - 0s 148ms/step\n",
            "1/1 [==============================] - 0s 157ms/step\n",
            "1/1 [==============================] - 0s 147ms/step\n",
            "1/1 [==============================] - 0s 146ms/step\n",
            "1/1 [==============================] - 0s 150ms/step\n",
            "1/1 [==============================] - 0s 142ms/step\n",
            "1/1 [==============================] - 0s 151ms/step\n",
            "1/1 [==============================] - 0s 150ms/step\n",
            "1/1 [==============================] - 0s 145ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 88ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 86ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 86ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 88ms/step\n",
            "1/1 [==============================] - 0s 88ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 138ms/step\n",
            "1/1 [==============================] - 1s 708ms/step\n",
            "4602\n",
            "4602\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbI25bS1vD7s"
      },
      "source": [
        "Let's reload the model, so you can try it side by side with the model that is still in memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUEWVskZjEF0"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# Write the list to a file using pickle.dump()\n",
        "with open('val_prediction_smallbert_cw.pkl', 'wb') as f:\n",
        "    pickle.dump(val_prediction, f)\n",
        "\n",
        "# Read the list from the file using pickle.load()\n",
        "# with open('val_prediction_smallbert_cw.pkl', 'rb') as f:\n",
        "#     prediction_list = pickle.load(f)\n",
        "\n",
        "# Write the list to a file using pickle.dump()\n",
        "with open('val_output_smallbert_cw.pkl', 'wb') as f:\n",
        "    pickle.dump(val_output, f)\n",
        "\n",
        "# Read the list from the file using pickle.load()\n",
        "# with open('val_output_smallbert_cw.pkl', 'rb') as f:\n",
        "#     output_list = pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(val_prediction).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd1pGXn3czj2",
        "outputId": "89d90447-ceb8-4666-e9e9-617a43bf3cb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4    3879\n",
              "3     672\n",
              "5      59\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Write the list to a file using pickle.dump()\n",
        "with open('val_prediction_smallbert_norm.pkl', 'wb') as f:\n",
        "    pickle.dump(val_prediction, f)\n",
        "\n",
        "# Read the list from the file using pickle.load()\n",
        "# with open('val_prediction_smallbert_cw.pkl', 'rb') as f:\n",
        "#     prediction_list = pickle.load(f)\n",
        "\n",
        "# Write the list to a file using pickle.dump()\n",
        "with open('val_output_smallbert_norm.pkl', 'wb') as f:\n",
        "    pickle.dump(val_output, f)\n",
        "\n",
        "# Read the list from the file using pickle.load()\n",
        "# with open('val_output_smallbert_cw.pkl', 'rb') as f:\n",
        "#     output_list = pickle.load(f)\n"
      ],
      "metadata": {
        "id": "ig1dbubA0Stv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_prediction = reloaded_model.predict(test_ds)\n",
        "\n",
        "import csv\n",
        "def read_numpy(test_prediction):\n",
        "  temp = test_prediction.argmax(axis = -1).astype(\"float64\")\n",
        "  temp += 3.0\n",
        "  return temp\n",
        "\n",
        "def write_csv(prediction):\n",
        "  with open('output.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow(['id', 'rating_label'])\n",
        "    for i, rating in enumerate(prediction):\n",
        "        writer.writerow([i+1, rating])\n",
        "\n",
        "write_csv(read_numpy(test_prediction))\n",
        "print(pd.DataFrame(read_numpy(test_prediction)).value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhhP7yKdzOgf",
        "outputId": "2e3699d3-e28e-4664-ae65-66497b984647"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "181/181 [==============================] - 529s 3s/step\n",
            "4.0    5049\n",
            "3.0     675\n",
            "5.0      42\n",
            "dtype: int64\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}